{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3ca4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tax_ids = [\"22817612\"]\n",
    "\n",
    "df = pd.DataFrame({\"tax_id\": tax_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b21a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?? Cache: 0 already processed.\n",
      "?? Starting crawl for 1 remaining companies (Total: 1)...\n",
      "\n",
      "[{'name': 'ФІЗИЧНІ ТА ЮРИДИЧНІ ОСОБИ', 'profile_link': None, 'country': None, 'role': 'Засновник', 'amount_uah': 3820000, 'share_percent': 100}, {'name': 'Сенчик Олександр Васильович', 'profile_link': 'https://opendatabot.ua/p/senchyk-oleksandr-vasylovych-h3AEVNL-pUlBFZK8qYH6Sg', 'country': 'Україна', 'role': 'Кінцевий бенефіціарний власник', 'amount_uah': None, 'share_percent': None}, {'name': 'Сенчик Олександр Олександрович', 'profile_link': 'https://opendatabot.ua/p/senchyk-oleksandr-oleksandrovych-ys9JRbFNUQ4PxV6PJ8tkww', 'country': 'Україна', 'role': 'Кінцевий бенефіціарний власник', 'amount_uah': None, 'share_percent': None}]\n",
      "[1/1] ID: 22817612 ? Success (3 owners)\n",
      "\n",
      "==============================\n",
      "?? CRAWL COMPLETE\n",
      "? New: 1\n",
      "??  Empty: 0\n",
      "? Failed: 0\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from fin_groups.db import OwnershipDB\n",
    "from fin_groups.crawler import CompanyCrawler\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "# 1. Initialize\n",
    "db = OwnershipDB(\"ownership.db\")\n",
    "crawler = CompanyCrawler(db=db)\n",
    "\n",
    "def run_company_crawler(db, tax_ids: List[str], cache_file: str = \"processed_ids.txt\", delay_range: tuple = (0.5, 1.5)):\n",
    "    \"\"\"\n",
    "    Runs the crawler with a local cache file to prevent redundant calls after a crash.\n",
    "    \"\"\"\n",
    "    crawler = CompanyCrawler(db=db)\n",
    "    \n",
    "    # 1. Load already processed IDs from cache\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            processed_ids = set(line.strip() for line in f)\n",
    "    \n",
    "    # 2. Filter the input list to exclude already processed ones\n",
    "    pending_ids = [str(tid).zfill(8) for tid in tax_ids if str(tid).zfill(8) not in processed_ids]\n",
    "    total_original = len(tax_ids)\n",
    "    total_pending = len(pending_ids)\n",
    "    \n",
    "    print(f\"?? Cache: {len(processed_ids)} already processed.\")\n",
    "    print(f\"?? Starting crawl for {total_pending} remaining companies (Total: {total_original})...\\n\")\n",
    "    \n",
    "    stats = {\"success\": 0, \"failed\": 0, \"empty\": 0}\n",
    "\n",
    "    for index, tid_str in enumerate(pending_ids, 1):\n",
    "        retries = 3\n",
    "        success = False\n",
    "        \n",
    "        while retries > 0 and not success:\n",
    "            try:\n",
    "                time.sleep(random.uniform(*delay_range))\n",
    "                \n",
    "                owners = crawler.crawl_company(tid_str)\n",
    "                \n",
    "                # We consider it \"processed\" if it succeeded OR if it's confirmed empty\n",
    "                # because we don't want to re-scrape empty companies every time.\n",
    "                if owners:\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ? Success ({len(owners)} owners)\")\n",
    "                    stats[\"success\"] += 1\n",
    "                else:\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ??  No owners found\")\n",
    "                    stats[\"empty\"] += 1\n",
    "                \n",
    "                # 3. Update Cache File immediately after success\n",
    "                with open(cache_file, \"a\") as f:\n",
    "                    f.write(f\"{tid_str}\\n\")\n",
    "                \n",
    "                success = True\n",
    "                \n",
    "            except Exception as e:\n",
    "                retries -= 1\n",
    "                if retries > 0:\n",
    "                    wait = 5 * (3 - retries)\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ?? Error: {e}. Retrying...\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ? Failed: {e}\")\n",
    "                    stats[\"failed\"] += 1\n",
    "\n",
    "    print(f\"\\n{'='*30}\\n?? CRAWL COMPLETE\\n? New: {stats['success']}\\n??  Empty: {stats['empty']}\\n? Failed: {stats['failed']}\\n{'='*30}\")\n",
    "\n",
    "# Execution\n",
    "run_company_crawler(db, df['tax_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ed96d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'33988668', '37829040', '38803128', '39765398', '42826722'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Set\n",
    "from fin_groups.db import OwnershipDB\n",
    "from fin_groups.normalize import company_entity_id\n",
    "\n",
    "def get_group_tax_ids(db: OwnershipDB, tax_id: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Given a company tax_id, return all tax_ids belonging to the same ownership group.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize tax_id exactly as crawler does\n",
    "    tax_id = str(tax_id).strip()\n",
    "    company_id = company_entity_id(\"UA\", tax_id)\n",
    "\n",
    "    # Ensure entity exists\n",
    "    if not db.get_entity(company_id):\n",
    "        return set()\n",
    "\n",
    "    # Get connected component (ownership group)\n",
    "    group_entity_ids = db.extract_group_ids(company_id)\n",
    "\n",
    "    if not group_entity_ids:\n",
    "        return set()\n",
    "\n",
    "    placeholders = \",\".join(\"?\" * len(group_entity_ids))\n",
    "\n",
    "    rows = db.query_rows(\n",
    "        f\"\"\"\n",
    "        SELECT DISTINCT tax_id\n",
    "        FROM entities\n",
    "        WHERE entity_id IN ({placeholders})\n",
    "          AND tax_id IS NOT NULL\n",
    "        \"\"\",\n",
    "        tuple(group_entity_ids)\n",
    "    )\n",
    "\n",
    "    return {row[\"tax_id\"] for row in rows}\n",
    "\n",
    "db = OwnershipDB(\"ownership.db\")\n",
    "\n",
    "get_group_tax_ids(db, \"38803128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32183e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DB_PATH = \"ownership.db\"  # or full Drive path if mounted\n",
    "\n",
    "def query_db(sql: str, params: tuple = ()):\n",
    "    \"\"\"\n",
    "    Execute SQL query on SQLite DB and return pandas DataFrame\n",
    "    \"\"\"\n",
    "    if not os.path.exists(DB_PATH):\n",
    "        raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n",
    "\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    try:\n",
    "        df = pd.read_sql_query(sql, conn, params=params)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "df_bad = query_db(\"\"\"\n",
    "    SELECT\n",
    "        owned_id,\n",
    "        SUM(share_percent) AS total_share\n",
    "    FROM ownerships\n",
    "    WHERE share_percent IS NOT NULL\n",
    "    GROUP BY owned_id\n",
    "    HAVING total_share > 100\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "print(len(df_bad))  # 3970\n",
    "\n",
    "df_bad[\"tax_id\"] = df_bad[\"owned_id\"].str.split(\":\").str[-1]\n",
    "bad_tax_ids = df_bad[\"tax_id\"].tolist()\n",
    "df_bad.to_excel(\"companies_to_reprocess.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
