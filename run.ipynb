{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3ca4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tax_ids = [\"22817612\"]\n",
    "\n",
    "df = pd.DataFrame({\"tax_id\": tax_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b21a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?? Cache: 0 already processed.\n",
      "?? Starting crawl for 1 remaining companies (Total: 1)...\n",
      "\n",
      "[{'name': 'ФІЗИЧНІ ТА ЮРИДИЧНІ ОСОБИ', 'profile_link': None, 'country': None, 'role': 'Засновник', 'amount_uah': 3820000, 'share_percent': 100}, {'name': 'Сенчик Олександр Васильович', 'profile_link': 'https://opendatabot.ua/p/senchyk-oleksandr-vasylovych-h3AEVNL-pUlBFZK8qYH6Sg', 'country': 'Україна', 'role': 'Кінцевий бенефіціарний власник', 'amount_uah': None, 'share_percent': None}, {'name': 'Сенчик Олександр Олександрович', 'profile_link': 'https://opendatabot.ua/p/senchyk-oleksandr-oleksandrovych-ys9JRbFNUQ4PxV6PJ8tkww', 'country': 'Україна', 'role': 'Кінцевий бенефіціарний власник', 'amount_uah': None, 'share_percent': None}]\n",
      "[1/1] ID: 22817612 ? Success (3 owners)\n",
      "\n",
      "==============================\n",
      "?? CRAWL COMPLETE\n",
      "? New: 1\n",
      "??  Empty: 0\n",
      "? Failed: 0\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from fin_groups.db import OwnershipDB\n",
    "from fin_groups.crawler import CompanyCrawler\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "# 1. Initialize\n",
    "db = OwnershipDB(\"ownership.db\")\n",
    "crawler = CompanyCrawler(db=db)\n",
    "\n",
    "def run_company_crawler(db, tax_ids: List[str], cache_file: str = \"processed_ids.txt\", delay_range: tuple = (0.5, 1.5)):\n",
    "    \"\"\"\n",
    "    Runs the crawler with a local cache file to prevent redundant calls after a crash.\n",
    "    \"\"\"\n",
    "    crawler = CompanyCrawler(db=db)\n",
    "    \n",
    "    # 1. Load already processed IDs from cache\n",
    "    processed_ids = set()\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, \"r\") as f:\n",
    "            processed_ids = set(line.strip() for line in f)\n",
    "    \n",
    "    # 2. Filter the input list to exclude already processed ones\n",
    "    pending_ids = [str(tid).zfill(8) for tid in tax_ids if str(tid).zfill(8) not in processed_ids]\n",
    "    total_original = len(tax_ids)\n",
    "    total_pending = len(pending_ids)\n",
    "    \n",
    "    print(f\"?? Cache: {len(processed_ids)} already processed.\")\n",
    "    print(f\"?? Starting crawl for {total_pending} remaining companies (Total: {total_original})...\\n\")\n",
    "    \n",
    "    stats = {\"success\": 0, \"failed\": 0, \"empty\": 0}\n",
    "\n",
    "    for index, tid_str in enumerate(pending_ids, 1):\n",
    "        retries = 3\n",
    "        success = False\n",
    "        \n",
    "        while retries > 0 and not success:\n",
    "            try:\n",
    "                time.sleep(random.uniform(*delay_range))\n",
    "                \n",
    "                owners = crawler.crawl_company(tid_str)\n",
    "                \n",
    "                # We consider it \"processed\" if it succeeded OR if it's confirmed empty\n",
    "                # because we don't want to re-scrape empty companies every time.\n",
    "                if owners:\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ? Success ({len(owners)} owners)\")\n",
    "                    stats[\"success\"] += 1\n",
    "                else:\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ??  No owners found\")\n",
    "                    stats[\"empty\"] += 1\n",
    "                \n",
    "                # 3. Update Cache File immediately after success\n",
    "                with open(cache_file, \"a\") as f:\n",
    "                    f.write(f\"{tid_str}\\n\")\n",
    "                \n",
    "                success = True\n",
    "                \n",
    "            except Exception as e:\n",
    "                retries -= 1\n",
    "                if retries > 0:\n",
    "                    wait = 5 * (3 - retries)\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ?? Error: {e}. Retrying...\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    print(f\"[{index}/{total_pending}] ID: {tid_str} ? Failed: {e}\")\n",
    "                    stats[\"failed\"] += 1\n",
    "\n",
    "    print(f\"\\n{'='*30}\\n?? CRAWL COMPLETE\\n? New: {stats['success']}\\n??  Empty: {stats['empty']}\\n? Failed: {stats['failed']}\\n{'='*30}\")\n",
    "\n",
    "# Execution\n",
    "run_company_crawler(db, df['tax_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82ed96d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'33988668', '37829040', '38803128', '39765398', '42826722'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Set\n",
    "from fin_groups.db import OwnershipDB\n",
    "from fin_groups.normalize import company_entity_id\n",
    "\n",
    "def get_group_tax_ids(db: OwnershipDB, tax_id: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Given a company tax_id, return all tax_ids belonging to the same ownership group.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize tax_id exactly as crawler does\n",
    "    tax_id = str(tax_id).strip()\n",
    "    company_id = company_entity_id(\"UA\", tax_id)\n",
    "\n",
    "    # Ensure entity exists\n",
    "    if not db.get_entity(company_id):\n",
    "        return set()\n",
    "\n",
    "    # Get connected component (ownership group)\n",
    "    group_entity_ids = db.extract_group_ids(company_id)\n",
    "\n",
    "    if not group_entity_ids:\n",
    "        return set()\n",
    "\n",
    "    placeholders = \",\".join(\"?\" * len(group_entity_ids))\n",
    "\n",
    "    rows = db.query_rows(\n",
    "        f\"\"\"\n",
    "        SELECT DISTINCT tax_id\n",
    "        FROM entities\n",
    "        WHERE entity_id IN ({placeholders})\n",
    "          AND tax_id IS NOT NULL\n",
    "        \"\"\",\n",
    "        tuple(group_entity_ids)\n",
    "    )\n",
    "\n",
    "    return {row[\"tax_id\"] for row in rows}\n",
    "\n",
    "db = OwnershipDB(\"ownership.db\")\n",
    "\n",
    "get_group_tax_ids(db, \"38803128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32183e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DB_PATH = \"ownership.db\"  # or full Drive path if mounted\n",
    "\n",
    "def query_db(sql: str, params: tuple = ()):\n",
    "    \"\"\"\n",
    "    Execute SQL query on SQLite DB and return pandas DataFrame\n",
    "    \"\"\"\n",
    "    if not os.path.exists(DB_PATH):\n",
    "        raise FileNotFoundError(f\"Database not found at {DB_PATH}\")\n",
    "\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    try:\n",
    "        df = pd.read_sql_query(sql, conn, params=params)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return df\n",
    "\n",
    "df_bad = query_db(\"\"\"\n",
    "    SELECT\n",
    "        owned_id,\n",
    "        SUM(share_percent) AS total_share\n",
    "    FROM ownerships\n",
    "    WHERE share_percent IS NOT NULL\n",
    "    GROUP BY owned_id\n",
    "    HAVING total_share > 100\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "print(len(df_bad))  # 3970\n",
    "\n",
    "df_bad[\"tax_id\"] = df_bad[\"owned_id\"].str.split(\":\").str[-1]\n",
    "bad_tax_ids = df_bad[\"tax_id\"].tolist()\n",
    "df_bad.to_excel(\"companies_to_reprocess.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319c3fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23196\\334526387.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mdb_tax_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_db_tax_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDB_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[0mdf_revenue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_revenue_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mREVENUE_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mREVENUE_TAX_COL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m df_missing = df_revenue[\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23196\\334526387.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(db_path)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tax_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[1;33m.\u001b[0m\u001b[0mto_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Yugin\\Desktop\\data-env\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_set'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DB_PATH = \"ownership.db\"\n",
    "REVENUE_FILE = \"firms_with_revenue_2024.xlsx\"\n",
    "REVENUE_TAX_COL = \"tax_id\"\n",
    "\n",
    "\n",
    "def load_db_tax_ids(db_path: str) -> set[str]:\n",
    "    if not os.path.exists(db_path):\n",
    "        raise FileNotFoundError(db_path)\n",
    "\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    try:\n",
    "        df = pd.read_sql_query(\n",
    "            \"\"\"\n",
    "            SELECT DISTINCT tax_id\n",
    "            FROM entities\n",
    "            WHERE entity_type = 'company'\n",
    "              AND tax_id IS NOT NULL\n",
    "            \"\"\",\n",
    "            conn,\n",
    "        )\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    return set(\n",
    "        df[\"tax_id\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.zfill(8)\n",
    "    )\n",
    "\n",
    "\n",
    "def load_revenue_df(path: str, tax_col: str) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, dtype={tax_col: str})\n",
    "\n",
    "    df[tax_col] = (\n",
    "        df[tax_col]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.zfill(8)\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "db_tax_ids = load_db_tax_ids(DB_PATH)\n",
    "df_revenue = load_revenue_df(REVENUE_FILE, REVENUE_TAX_COL)\n",
    "\n",
    "df_missing = df_revenue[\n",
    "    ~df_revenue[REVENUE_TAX_COL].isin(db_tax_ids)\n",
    "].copy()\n",
    "\n",
    "print(f\"Companies in revenue file      : {len(df_revenue)}\")\n",
    "print(f\"Companies already in DB        : {len(db_tax_ids)}\")\n",
    "print(f\"❌ Missing in DB (to process) : {len(df_missing)}\")\n",
    "\n",
    "df_missing.to_excel(\n",
    "    \"companies_missing_in_db.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
